{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Ax34kp2sOJ53"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cairosvg\n",
        "!pip install svgpathtools cairosvg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D44vH-VmUOr8",
        "outputId": "58b1f29d-5687-4431-d3e5-54b05163a57a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cairosvg in /usr/local/lib/python3.10/dist-packages (2.7.1)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.7.1)\n",
            "Requirement already satisfied: cssselect2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (9.4.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.22)\n",
            "Requirement already satisfied: svgpathtools in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: cairosvg in /usr/local/lib/python3.10/dist-packages (2.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from svgpathtools) (1.26.4)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from svgpathtools) (1.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from svgpathtools) (1.13.1)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.7.1)\n",
            "Requirement already satisfied: cssselect2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (9.4.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cairosvg\n",
        "import svgpathtools"
      ],
      "metadata": {
        "id": "8S8LNjSZUbNm"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(csv_path):\n",
        "    data = pd.read_csv(csv_path, header=None, names=[\"PathID\", \"PointID\", \"X\", \"Y\"])\n",
        "    return data\n",
        "\n",
        "def clean_data(data):\n",
        "    data['PathID'] = data['PathID'].astype(int)\n",
        "    data['PointID'] = data['PointID'].astype(int)\n",
        "    cleaned_data = data.drop_duplicates(subset=['PathID', 'PointID', 'X', 'Y']).reset_index(drop=True)\n",
        "    return cleaned_data\n",
        "\n",
        "def visualize_data(data):\n",
        "    plt.scatter(data['X'], data['Y'], c='blue', marker='o')\n",
        "    plt.title('Scatter Plot of Raw Data')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.show()\n",
        "\n",
        "def segment_paths(data, threshold=10):\n",
        "    data['NewPathID'] = 0\n",
        "    last_index = 0\n",
        "    for i in range(1, len(data)):\n",
        "        dist = np.linalg.norm(data.iloc[i][['X', 'Y']].values - data.iloc[i-1][['X', 'Y']].values)\n",
        "        if dist > threshold:\n",
        "            last_index += 1\n",
        "        data.at[i, 'NewPathID'] = last_index\n",
        "    return data\n",
        "\n",
        "def normalize_data(data):\n",
        "    data['X'] = (data['X'] - data['X'].min()) / (data['X'].max() - data['X'].min())\n",
        "    data['Y'] = (data['Y'] - data['Y'].min()) / (data['Y'].max() - data['Y'].min())\n",
        "    return data\n",
        "\n",
        "def augment_data(data):\n",
        "    theta = np.radians(30)\n",
        "    c, s = np.cos(theta), np.sin(theta)\n",
        "    data['X_rot'] = data['X'] * c - data['Y'] * s\n",
        "    data['Y_rot'] = data['X'] * s + data['Y'] * c\n",
        "    scale_factor = 1.2\n",
        "    data['X_scale'] = data['X'] * scale_factor\n",
        "    data['Y_scale'] = data['Y'] * scale_factor\n",
        "    translate_x, translate_y = 0.1, 0.1\n",
        "    data['X_trans'] = data['X'] + translate_x\n",
        "    data['Y_trans'] = data['Y'] + translate_y\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "v-_TiayvPUKi"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bezier_curve(P0, P1, P2, P3, t):\n",
        "    return (1-t)**3 * P0 + 3*(1-t)**2 * t * P1 + 3*(1-t) * t**2 * P2 + t**3 * P3\n",
        "\n",
        "def fit_bezier_curve(data, n_segments=10):\n",
        "    segments = np.array_split(data[['X', 'Y']].values, n_segments)\n",
        "    bezier_paths = []\n",
        "    for segment in segments:\n",
        "        P0 = segment[0]\n",
        "        P3 = segment[-1]\n",
        "        P1 = segment[len(segment) // 3]\n",
        "        P2 = segment[2 * len(segment) // 3]\n",
        "        t_values = np.linspace(0, 1, 100)\n",
        "        bezier_points = np.array([bezier_curve(P0, P1, P2, P3, t) for t in t_values])\n",
        "        bezier_paths.append(bezier_points)\n",
        "    return bezier_paths\n",
        "\n",
        "def polyline_to_image(polyline, image_size=(64, 64), line_thickness=2):\n",
        "    image = np.ones(image_size, dtype=np.uint8) * 255\n",
        "    polyline = np.array(polyline)\n",
        "    polyline[:, 0] = np.interp(polyline[:, 0], (polyline[:, 0].min(), polyline[:, 0].max()), (0, image_size[0] - 1))\n",
        "    polyline[:, 1] = np.interp(polyline[:, 1], (polyline[:, 1].min(), polyline[:, 1].max()), (0, image_size[1] - 1))\n",
        "    polyline = polyline.astype(int)\n",
        "    cv2.polylines(image, [polyline], isClosed=False, color=(0,), thickness=line_thickness)\n",
        "    return image\n",
        "\n",
        "def save_polyline_as_image(points, path, file_name):\n",
        "    plt.figure(figsize=(64 / 100, 64 / 100), dpi=100)\n",
        "    plt.plot(points[:, 0], points[:, 1], marker='o')\n",
        "    plt.xlim(0, 1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.axis('off')\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    plt.savefig(os.path.join(path, file_name), bbox_inches='tight', pad_inches=0, cmap='gray')\n",
        "    plt.close()\n",
        "\n",
        "def generate_images_from_csv(data, output_path):\n",
        "    for path_id in data['PathID'].unique():\n",
        "        subset = data[data['PathID'] == path_id]\n",
        "        polyline = subset[['X', 'Y']].values\n",
        "        image = polyline_to_image(polyline)\n",
        "        Image.fromarray(image).save(os.path.join(output_path, f'path_{path_id}.png'))\n"
      ],
      "metadata": {
        "id": "rVBhe0DvOq07"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_directory(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def process_svg(svg_path, output_path):\n",
        "    \"\"\"\n",
        "    Convert an SVG file to PNG and save it in the specified directory.\n",
        "\n",
        "    Args:\n",
        "    - svg_path (str): Path to the SVG file.\n",
        "    - output_path (str): Directory to save the converted PNG file.\n",
        "    \"\"\"\n",
        "    # Create the output directory if it doesn't exist\n",
        "    create_directory(output_path)\n",
        "\n",
        "    # Define the path for the PNG file\n",
        "    png_path = os.path.join(output_path, 'converted_image.png')\n",
        "\n",
        "    # Convert SVG to PNG\n",
        "    cairosvg.svg2png(url=svg_path, write_to=png_path)\n",
        "\n",
        "    print(f\"Converted SVG file saved to: {png_path}\")\n",
        "\n",
        "def svg_to_points(svg_path):\n",
        "    \"\"\"\n",
        "    Extract points from an SVG path file and return them.\n",
        "\n",
        "    Args:\n",
        "    - svg_path (str): Path to the SVG file.\n",
        "\n",
        "    Returns:\n",
        "    - points (list): List of (x, y) tuples.\n",
        "    \"\"\"\n",
        "    paths, attributes = svgpathtools.svg2paths(svg_path)\n",
        "    points = []\n",
        "\n",
        "    for path in paths:\n",
        "        for segment in path:\n",
        "            if isinstance(segment, svgpathtools.Line):\n",
        "                points.append((segment.start.real, segment.start.imag))\n",
        "                points.append((segment.end.real, segment.end.imag))\n",
        "            elif isinstance(segment, svgpathtools.CubicBezier):\n",
        "                t_values = np.linspace(0, 1, 10)\n",
        "                for t in t_values:\n",
        "                    point = segment.point(t)\n",
        "                    points.append((point.real, point.imag))\n",
        "\n",
        "    return points\n",
        "\n",
        "def plot_points(points, output_file):\n",
        "    \"\"\"\n",
        "    Plot points and save the plot as an image.\n",
        "\n",
        "    Args:\n",
        "    - points (list): List of (x, y) tuples.\n",
        "    - output_file (str): Path to save the image.\n",
        "    \"\"\"\n",
        "    x, y = zip(*points)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.plot(x, y, 'o')\n",
        "    plt.title('SVG Path Points')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.axis('equal')\n",
        "    plt.savefig(output_file, bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "uek8Q5AUOpk0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path1 = 'https://raw.githubusercontent.com/Harshsinghr/Curvetopia-Adobe-GenSolve-Round2/main/Data/problems/occlusion1.csv'\n",
        "csv_path2 = 'https://raw.githubusercontent.com/Harshsinghr/Curvetopia-Adobe-GenSolve-Round2/main/Data/problems/occlusion2.csv'\n",
        "output_dir1 = '/output_images/occlusion1'\n",
        "output_dir2 = '/output_images/occlusion2'\n",
        "create_directory(output_dir1)\n",
        "create_directory(output_dir2)\n",
        "svg_path1 = 'https://raw.githubusercontent.com/Harshsinghr/Curvetopia-Adobe-GenSolve-Round2/main/Data/problems/occlusion1.svg'\n",
        "svg_path2 = 'https://raw.githubusercontent.com/Harshsinghr/Curvetopia-Adobe-GenSolve-Round2/main/Data/problems/occlusion2.svg'\n",
        "\n",
        "process_csv(csv_path1, output_dir1)\n",
        "process_csv(csv_path2, output_dir2)\n",
        "\n",
        "svg_output_dir1 = '/output_images/occlusion1_svg'\n",
        "svg_output_dir2 = '/output_images/occlusion2_svg'\n",
        "\n",
        "# Convert SVG to PNG\n",
        "process_svg(svg_path1, svg_output_dir1)\n",
        "process_svg(svg_path2, svg_output_dir2)\n",
        "\n",
        "# Extract points from SVG and plot\n",
        "points1 = svg_to_points(svg_path1)\n",
        "points2 = svg_to_points(svg_path2)\n",
        "\n",
        "# Save plotted points as images\n",
        "plot_points(points1, os.path.join(svg_output_dir1, 'points_plot.png'))\n",
        "plot_points(points2, os.path.join(svg_output_dir2, 'points_plot.png'))\n",
        "\n"
      ],
      "metadata": {
        "id": "FDJP90sYQ0Dc"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define and compile the model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(6, activation='softmax')(x)  # Number of classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up data generators for training\n",
        "# Set up data generators with improved augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Rs3F1VdIQ0vn"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/output_images'  # Update with your actual path\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/output_images',\n",
        "    target_size=(64, 64),\n",
        "    color_mode='rgb',  # Changed to RGB for pre-trained model\n",
        "    class_mode='categorical',\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=20, callbacks=[early_stopping, lr_reduction])\n",
        "\n",
        "print(\"Model training complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsq2XVTAQ5Ko",
        "outputId": "5b57db60-dd21-4a1e-b03d-b959be061013"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13 images belonging to 6 classes.\n",
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - accuracy: 0.1538 - loss: 1.8759 - learning_rate: 0.0010\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.3846 - loss: 1.6408 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.6154 - loss: 1.3138 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.6923 - loss: 1.2224 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.7692 - loss: 1.0516 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7692 - loss: 0.8438 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.6923 - loss: 0.7488 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.6923 - loss: 0.7463 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.6923 - loss: 0.6996 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.6923 - loss: 0.9380 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.6923 - loss: 0.7714 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.6923 - loss: 0.7060 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.6923 - loss: 0.7552 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7692 - loss: 0.6601 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.6923 - loss: 0.6097 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.7692 - loss: 0.4795 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.8462 - loss: 0.4778 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.6923 - loss: 0.5912 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - accuracy: 0.6923 - loss: 0.5930 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - accuracy: 0.7692 - loss: 0.5934 - learning_rate: 0.0010\n",
            "Model training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjs4Ye0xQ-9W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u3w4djf7RB5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}